core@ip-172-31-44-124 ~/pres-spark-demo $ sudo weave run --with-dns 10.10.1.88/24 --tty --interactive --hostname=spark-shell.weave.local --name=spark-shell errordeveloper/weave-spark-shell-minimal:latest --master spark://spark-master-gce.weave.local:7077 --jars /usr/spark/lib/elasticsearch-spark_2.10-2.1.0.Beta3.jar && docker attach spark-shell
a4d109c1fae27ddfe4b16913ed8ac712917b2fb037518194ebb2cc10eceda2aa
Spark assembly has been built with Hive, including Datanucleus jars on classpath
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
14/12/02 15:44:17 INFO SecurityManager: Changing view acls to: root,
14/12/02 15:44:17 INFO SecurityManager: Changing modify acls to: root,
14/12/02 15:44:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root, ); users with modify permissions: Set(root, )
14/12/02 15:44:17 INFO HttpServer: Starting HTTP Server
14/12/02 15:44:17 INFO Utils: Successfully started service 'HTTP class server' on port 38027.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.1.0
      /_/

Using Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_25)
Type in expressions to have them evaluated.
Type :help for more information.
14/12/02 15:44:21 INFO SecurityManager: Changing view acls to: root,
14/12/02 15:44:21 INFO SecurityManager: Changing modify acls to: root,
14/12/02 15:44:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root, ); users with modify permissions: Set(root, )
14/12/02 15:44:21 INFO Slf4jLogger: Slf4jLogger started
14/12/02 15:44:21 INFO Remoting: Starting remoting
14/12/02 15:44:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@spark-shell.weave.local:56845]
14/12/02 15:44:22 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriver@spark-shell.weave.local:56845]
14/12/02 15:44:22 INFO Utils: Successfully started service 'sparkDriver' on port 56845.
14/12/02 15:44:22 INFO SparkEnv: Registering MapOutputTracker
14/12/02 15:44:22 INFO SparkEnv: Registering BlockManagerMaster
14/12/02 15:44:22 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20141202154422-b2fb
14/12/02 15:44:22 INFO Utils: Successfully started service 'Connection manager for block manager' on port 47051.
14/12/02 15:44:22 INFO ConnectionManager: Bound socket to port 47051 with id = ConnectionManagerId(spark-shell.weave.local,47051)
14/12/02 15:44:22 INFO MemoryStore: MemoryStore started with capacity 265.1 MB
14/12/02 15:44:22 INFO BlockManagerMaster: Trying to register BlockManager
14/12/02 15:44:22 INFO BlockManagerMasterActor: Registering block manager spark-shell.weave.local:47051 with 265.1 MB RAM
14/12/02 15:44:22 INFO BlockManagerMaster: Registered BlockManager
14/12/02 15:44:22 INFO HttpFileServer: HTTP File server directory is /tmp/spark-53cfd71e-4679-48c4-8af3-f46aed2155ce
14/12/02 15:44:22 INFO HttpServer: Starting HTTP Server
14/12/02 15:44:22 INFO Utils: Successfully started service 'HTTP file server' on port 47257.
14/12/02 15:44:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
14/12/02 15:44:32 INFO SparkUI: Started SparkUI at http://spark-shell.weave.local:4040
14/12/02 15:44:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/12/02 15:44:33 INFO SparkContext: Added JAR file:/usr/spark/lib/elasticsearch-spark_2.10-2.1.0.Beta3.jar at http://10.10.1.88:47257/jars/elasticsearch-spark_2.10-2.1.0.Beta3.jar with timestamp 1417535073460
14/12/02 15:44:33 INFO AppClient$ClientActor: Connecting to master spark://spark-master-gce.weave.local:7077...
14/12/02 15:44:33 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
14/12/02 15:44:33 INFO SparkILoop: Created spark context..
Spark context available as sc.

scala> 14/12/02 15:44:34 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20141202154434-0002
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor added: app-20141202154434-0002/0 on worker-20141202140948-spark-worker-aws-0.weave.local-56075 (spark-worker-aws-0.weave.local:56075) with 4 cores
14/12/02 15:44:34 INFO SparkDeploySchedulerBackend: Granted executor ID app-20141202154434-0002/0 on hostPort spark-worker-aws-0.weave.local:56075 with 4 cores, 512.0 MB RAM
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor added: app-20141202154434-0002/1 on worker-20141202140945-spark-worker-aws-2.weave.local-46105 (spark-worker-aws-2.weave.local:46105) with 4 cores
14/12/02 15:44:34 INFO SparkDeploySchedulerBackend: Granted executor ID app-20141202154434-0002/1 on hostPort spark-worker-aws-2.weave.local:46105 with 4 cores, 512.0 MB RAM
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor added: app-20141202154434-0002/2 on worker-20141202140950-spark-worker-aws-1.weave.local-42239 (spark-worker-aws-1.weave.local:42239) with 4 cores
14/12/02 15:44:34 INFO SparkDeploySchedulerBackend: Granted executor ID app-20141202154434-0002/2 on hostPort spark-worker-aws-1.weave.local:42239 with 4 cores, 512.0 MB RAM
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor added: app-20141202154434-0002/3 on worker-20141202140909-spark-worker-gce-1.weave.local-39948 (spark-worker-gce-1.weave.local:39948) with 1 cores
14/12/02 15:44:34 INFO SparkDeploySchedulerBackend: Granted executor ID app-20141202154434-0002/3 on hostPort spark-worker-gce-1.weave.local:39948 with 1 cores, 512.0 MB RAM
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor added: app-20141202154434-0002/4 on worker-20141202140915-spark-worker-gce-2.weave.local-48815 (spark-worker-gce-2.weave.local:48815) with 1 cores
14/12/02 15:44:34 INFO SparkDeploySchedulerBackend: Granted executor ID app-20141202154434-0002/4 on hostPort spark-worker-gce-2.weave.local:48815 with 1 cores, 512.0 MB RAM
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor updated: app-20141202154434-0002/3 is now RUNNING
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor updated: app-20141202154434-0002/4 is now RUNNING
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor updated: app-20141202154434-0002/0 is now RUNNING
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor updated: app-20141202154434-0002/1 is now RUNNING
14/12/02 15:44:34 INFO AppClient$ClientActor: Executor updated: app-20141202154434-0002/2 is now RUNNING
14/12/02 15:44:37 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@spark-worker-aws-1.weave.local:34625/user/Executor#-776677722] with ID 2
14/12/02 15:44:37 INFO BlockManagerMasterActor: Registering block manager spark-worker-aws-1.weave.local:34187 with 265.1 MB RAM
14/12/02 15:44:38 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@spark-worker-aws-0.weave.local:43993/user/Executor#-1965329951] with ID 0
14/12/02 15:44:38 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@spark-worker-aws-2.weave.local:43055/user/Executor#-1312054579] with ID 1
14/12/02 15:44:39 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@spark-worker-gce-2.weave.local:58683/user/Executor#-1109005964] with ID 4
14/12/02 15:44:39 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@spark-worker-gce-1.weave.local:47386/user/Executor#-705189784] with ID 3
14/12/02 15:44:39 INFO BlockManagerMasterActor: Registering block manager spark-worker-gce-2.weave.local:42653 with 267.3 MB RAM
14/12/02 15:44:40 INFO BlockManagerMasterActor: Registering block manager spark-worker-gce-1.weave.local:56687 with 267.3 MB RAM
14/12/02 15:44:40 INFO BlockManagerMasterActor: Registering block manager spark-worker-aws-0.weave.local:43691 with 265.1 MB RAM
14/12/02 15:44:40 INFO BlockManagerMasterActor: Registering block manager spark-worker-aws-2.weave.local:37387 with 265.1 MB RAM


scala> import org.elasticsearch.spark._
import org.elasticsearch.spark._

scala> import org.apache.hadoop.mapreduce._
import org.apache.hadoop.mapreduce._

scala> import org.elasticsearch.hadoop.cfg._
import org.elasticsearch.hadoop.cfg._

scala> import org.elasticsearch.hadoop.mr._
import org.elasticsearch.hadoop.mr._

scala> import org.apache.hadoop.io._
import org.apache.hadoop.io._

scala> val es_master = "elasticsearch-gce-0.weave.local"
es_master: String = elasticsearch-gce-0.weave.local

scala> val conf = new Configuration()
<console>:25: error: not found: type Configuration
       val conf = new Configuration()
                      ^

scala> import org.elasticsearch.hadoop.conf._
<console>:25: error: object conf is not a member of package org.elasticsearch.hadoop
       import org.elasticsearch.hadoop.conf._
                                       ^

scala> import org.apache.hadoop.conf._
import org.apache.hadoop.conf._

scala> val conf = new Configuration()
conf: org.apache.hadoop.conf.Configuration = Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml

scala> conf.set("es.nodes", es_master)

scala> conf.set("es.nodes.discovery", "true")

scala> conf.set("es.resource", "twitter/status")

scala> conf.set("es.query", "?q=me*")

scala> val esRDD = sc.newAPIHadoopRDD(conf, classOf[EsInputFormat[Text, MapWritable]], classOf[Text], classOf[MapWritable])
14/12/02 15:49:44 INFO MemoryStore: ensureFreeSpace(67949) called with curMem=0, maxMem=278019440
14/12/02 15:49:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 66.4 KB, free 265.1 MB)
14/12/02 15:49:44 INFO MemoryStore: ensureFreeSpace(6072) called with curMem=67949, maxMem=278019440
14/12/02 15:49:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.9 KB, free 265.1 MB)
14/12/02 15:49:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-shell.weave.local:47051 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:49:44 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
esRDD: org.apache.spark.rdd.RDD[(org.apache.hadoop.io.Text, org.apache.hadoop.io.MapWritable)] = NewHadoopRDD[0] at newAPIHadoopRDD at <console>:32

scala> conf.set("es.query", "?q=docker")

scala> val esRDD = sc.newAPIHadoopRDD(conf, classOf[EsInputFormat[Text, MapWritable]], classOf[Text], classOf[MapWritable])
14/12/02 15:50:10 INFO MemoryStore: ensureFreeSpace(68028) called with curMem=74021, maxMem=278019440
14/12/02 15:50:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 66.4 KB, free 265.0 MB)
14/12/02 15:50:10 INFO MemoryStore: ensureFreeSpace(6066) called with curMem=142049, maxMem=278019440
14/12/02 15:50:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KB, free 265.0 MB)
14/12/02 15:50:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-shell.weave.local:47051 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:50:10 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
esRDD: org.apache.spark.rdd.RDD[(org.apache.hadoop.io.Text, org.apache.hadoop.io.MapWritable)] = NewHadoopRDD[1] at newAPIHadoopRDD at <console>:32

scala> esRDD.count()
14/12/02 15:50:24 INFO Version: Elasticsearch Hadoop v2.1.0.Beta3 [157763564e]
14/12/02 15:50:24 INFO EsInputFormat: Reading from [twitter/status]
14/12/02 15:50:25 INFO EsInputFormat: Discovered mapping {twitter=[mappings=[status=[created_at=DATE, hashtag=[end=LONG, start=LONG, text=STRING], in_reply=[status=LONG, user_id=LONG, user_screen_name=STRING], language=STRING, link=[display_url=STRING, end=LONG, expand_url=STRING, start=LONG, url=STRING], location=GEO_POINT, mention=[end=LONG, id=LONG, name=STRING, screen_name=STRING, start=LONG], place=[country=STRING, country_code=STRING, full_name=STRING, id=STRING, name=STRING, type=STRING, url=STRING], retweet=[id=LONG, retweet_count=LONG, user_id=LONG, user_screen_name=STRING], retweet_count=LONG, source=STRING, text=STRING, truncated=BOOLEAN, user=[description=STRING, id=LONG, location=STRING, name=STRING, profile_image_url=STRING, profile_image_url_https=STRING, screen_name=STRING]]]]} for [twitter/status]
14/12/02 15:50:25 INFO EsInputFormat: Created [5] shard-splits
14/12/02 15:50:25 INFO SparkContext: Starting job: count at <console>:35
14/12/02 15:50:25 INFO DAGScheduler: Got job 0 (count at <console>:35) with 5 output partitions (allowLocal=false)
14/12/02 15:50:25 INFO DAGScheduler: Final stage: Stage 0(count at <console>:35)
14/12/02 15:50:25 INFO DAGScheduler: Parents of final stage: List()
14/12/02 15:50:25 INFO DAGScheduler: Missing parents: List()
14/12/02 15:50:25 INFO DAGScheduler: Submitting Stage 0 (NewHadoopRDD[1] at newAPIHadoopRDD at <console>:32), which has no missing parents
14/12/02 15:50:25 INFO MemoryStore: ensureFreeSpace(1568) called with curMem=148115, maxMem=278019440
14/12/02 15:50:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 1568.0 B, free 265.0 MB)
14/12/02 15:50:25 INFO MemoryStore: ensureFreeSpace(1013) called with curMem=149683, maxMem=278019440
14/12/02 15:50:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1013.0 B, free 265.0 MB)
14/12/02 15:50:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-shell.weave.local:47051 (size: 1013.0 B, free: 265.1 MB)
14/12/02 15:50:25 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
14/12/02 15:50:25 INFO DAGScheduler: Submitting 5 missing tasks from Stage 0 (NewHadoopRDD[1] at newAPIHadoopRDD at <console>:32)
14/12/02 15:50:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
14/12/02 15:50:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, spark-worker-aws-1.weave.local, ANY, 13833 bytes)
14/12/02 15:50:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, spark-worker-gce-2.weave.local, ANY, 13839 bytes)
14/12/02 15:50:25 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, spark-worker-aws-0.weave.local, ANY, 13833 bytes)
14/12/02 15:50:25 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, spark-worker-aws-2.weave.local, ANY, 13832 bytes)
14/12/02 15:50:25 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, spark-worker-gce-1.weave.local, ANY, 13834 bytes)
14/12/02 15:50:25 INFO ConnectionManager: Accepted connection from [spark-worker-aws-1.weave.local/10.10.1.31:57898]
14/12/02 15:50:25 INFO SendingConnection: Initiating connection to [spark-worker-aws-1.weave.local/10.10.1.31:34187]
14/12/02 15:50:25 INFO SendingConnection: Connected to [spark-worker-aws-1.weave.local/10.10.1.31:34187], 1 messages pending
14/12/02 15:50:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-worker-aws-1.weave.local:34187 (size: 1013.0 B, free: 265.1 MB)
14/12/02 15:50:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-worker-aws-1.weave.local:34187 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:50:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1525 ms on spark-worker-aws-1.weave.local (1/5)
14/12/02 15:50:37 INFO ConnectionManager: Accepted connection from [10.10.1.12/10.10.1.12:34949]
14/12/02 15:50:47 INFO SendingConnection: Initiating connection to [/10.10.1.12:42653]
14/12/02 15:50:47 INFO SendingConnection: Connected to [/10.10.1.12:42653], 1 messages pending
14/12/02 15:51:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-worker-gce-2.weave.local:42653 (size: 1013.0 B, free: 267.3 MB)
14/12/02 15:51:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-worker-aws-0.weave.local:43691 (size: 1013.0 B, free: 265.1 MB)
14/12/02 15:51:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-worker-aws-2.weave.local:37387 (size: 1013.0 B, free: 265.1 MB)
14/12/02 15:51:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-worker-gce-2.weave.local:42653 (size: 5.9 KB, free: 267.3 MB)
14/12/02 15:51:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 64462 ms on spark-worker-gce-2.weave.local (2/5)
14/12/02 15:51:37 INFO ConnectionManager: Accepted connection from [10.10.1.11/10.10.1.11:56484]
14/12/02 15:51:47 INFO ConnectionManager: Accepted connection from [10.10.1.30/10.10.1.30:49132]
14/12/02 15:51:57 INFO ConnectionManager: Accepted connection from [10.10.1.32/10.10.1.32:55862]
14/12/02 15:52:07 INFO SendingConnection: Initiating connection to [/10.10.1.30:43691]
14/12/02 15:52:07 INFO SendingConnection: Initiating connection to [/10.10.1.32:37387]
14/12/02 15:52:07 INFO SendingConnection: Initiating connection to [/10.10.1.11:56687]
14/12/02 15:52:07 INFO SendingConnection: Connected to [/10.10.1.11:56687], 1 messages pending
14/12/02 15:52:07 INFO SendingConnection: Connected to [/10.10.1.30:43691], 1 messages pending
14/12/02 15:52:07 INFO SendingConnection: Connected to [/10.10.1.32:37387], 1 messages pending
14/12/02 15:52:26 WARN TaskSetManager: Lost task 4.0 in stage 0.0 (TID 4, spark-worker-gce-1.weave.local): java.io.IOException: unexpected exception type
        java.io.ObjectStreamClass.throwMiscException(ObjectStreamClass.java:1538)
        java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1025)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1896)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        java.lang.Thread.run(Thread.java:745)
14/12/02 15:52:26 INFO TaskSetManager: Starting task 4.1 in stage 0.0 (TID 5, spark-worker-gce-1.weave.local, ANY, 13834 bytes)
14/12/02 15:52:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-worker-aws-0.weave.local:43691 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:52:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-worker-aws-2.weave.local:37387 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:52:28 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 123136 ms on spark-worker-aws-0.weave.local (3/5)
14/12/02 15:52:28 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 123636 ms on spark-worker-aws-2.weave.local (4/5)
14/12/02 15:53:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-worker-gce-1.weave.local:56687 (size: 1013.0 B, free: 267.3 MB)
14/12/02 15:53:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-worker-gce-1.weave.local:56687 (size: 5.9 KB, free: 267.3 MB)
14/12/02 15:53:29 INFO TaskSetManager: Finished task 4.1 in stage 0.0 (TID 5) in 62250 ms on spark-worker-gce-1.weave.local (5/5)
14/12/02 15:53:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
14/12/02 15:53:29 INFO DAGScheduler: Stage 0 (count at <console>:35) finished in 183.843 s
14/12/02 15:53:29 INFO SparkContext: Job finished: count at <console>:35, took 183.900310308 s
res5: Long = 6

scalascala> conf.set("es.query", "?q=rocket")

scala> val esRDD = sc.newAPIHadoopRDD(conf, classOf[EsInputFormat[Text, MapWritable]], classOf[Text], classOf[MapWritable])
14/12/02 15:57:07 INFO MemoryStore: ensureFreeSpace(68076) called with curMem=150696, maxMem=278019440
14/12/02 15:57:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 66.5 KB, free 264.9 MB)
14/12/02 15:57:07 INFO MemoryStore: ensureFreeSpace(6062) called with curMem=218772, maxMem=278019440
14/12/02 15:57:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KB, free 264.9 MB)
14/12/02 15:57:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-shell.weave.local:47051 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:57:07 INFO BlockManagerMaster: Updated info of block broadcast_3_piece0
esRDD: org.apache.spark.rdd.RDD[(org.apache.hadoop.io.Text, org.apache.hadoop.io.MapWritable)] = NewHadoopRDD[2] at newAPIHadoopRDD at <console>:32

scala> esRDD.count()
14/12/02 15:57:13 INFO EsInputFormat: Reading from [twitter/status]
14/12/02 15:57:13 INFO EsInputFormat: Discovered mapping {twitter=[mappings=[status=[created_at=DATE, hashtag=[end=LONG, start=LONG, text=STRING], in_reply=[status=LONG, user_id=LONG, user_screen_name=STRING], language=STRING, link=[display_url=STRING, end=LONG, expand_url=STRING, start=LONG, url=STRING], location=GEO_POINT, mention=[end=LONG, id=LONG, name=STRING, screen_name=STRING, start=LONG], place=[country=STRING, country_code=STRING, full_name=STRING, id=STRING, name=STRING, type=STRING, url=STRING], retweet=[id=LONG, retweet_count=LONG, user_id=LONG, user_screen_name=STRING], retweet_count=LONG, source=STRING, text=STRING, truncated=BOOLEAN, user=[description=STRING, id=LONG, location=STRING, name=STRING, profile_image_url=STRING, profile_image_url_https=STRING, screen_name=STRING]]]]} for [twitter/status]
14/12/02 15:57:13 INFO EsInputFormat: Created [5] shard-splits
14/12/02 15:57:13 INFO SparkContext: Starting job: count at <console>:35
14/12/02 15:57:13 INFO DAGScheduler: Got job 1 (count at <console>:35) with 5 output partitions (allowLocal=false)
14/12/02 15:57:13 INFO DAGScheduler: Final stage: Stage 1(count at <console>:35)
14/12/02 15:57:13 INFO DAGScheduler: Parents of final stage: List()
14/12/02 15:57:13 INFO DAGScheduler: Missing parents: List()
14/12/02 15:57:13 INFO DAGScheduler: Submitting Stage 1 (NewHadoopRDD[2] at newAPIHadoopRDD at <console>:32), which has no missing parents
14/12/02 15:57:13 INFO MemoryStore: ensureFreeSpace(1568) called with curMem=224834, maxMem=278019440
14/12/02 15:57:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 1568.0 B, free 264.9 MB)
14/12/02 15:57:13 INFO MemoryStore: ensureFreeSpace(1015) called with curMem=226402, maxMem=278019440
14/12/02 15:57:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1015.0 B, free 264.9 MB)
14/12/02 15:57:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-shell.weave.local:47051 (size: 1015.0 B, free: 265.1 MB)
14/12/02 15:57:13 INFO BlockManagerMaster: Updated info of block broadcast_4_piece0
14/12/02 15:57:13 INFO DAGScheduler: Submitting 5 missing tasks from Stage 1 (NewHadoopRDD[2] at newAPIHadoopRDD at <console>:32)
14/12/02 15:57:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
14/12/02 15:57:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 6, spark-worker-gce-1.weave.local, ANY, 13832 bytes)
14/12/02 15:57:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 7, spark-worker-aws-0.weave.local, ANY, 13841 bytes)
14/12/02 15:57:13 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 8, spark-worker-gce-2.weave.local, ANY, 13830 bytes)
14/12/02 15:57:13 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 9, spark-worker-aws-2.weave.local, ANY, 13830 bytes)
14/12/02 15:57:13 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 10, spark-worker-aws-1.weave.local, ANY, 13841 bytes)
14/12/02 15:57:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-worker-aws-1.weave.local:34187 (size: 1015.0 B, free: 265.1 MB)
14/12/02 15:57:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-worker-aws-1.weave.local:34187 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:57:14 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 10) in 877 ms on spark-worker-aws-1.weave.local (1/5)
14/12/02 15:57:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-worker-gce-2.weave.local:42653 (size: 1015.0 B, free: 267.3 MB)
14/12/02 15:57:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-worker-gce-1.weave.local:56687 (size: 1015.0 B, free: 267.3 MB)
14/12/02 15:57:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-worker-aws-0.weave.local:43691 (size: 1015.0 B, free: 265.1 MB)
14/12/02 15:57:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on spark-worker-aws-2.weave.local:37387 (size: 1015.0 B, free: 265.1 MB)
14/12/02 15:57:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-worker-gce-1.weave.local:56687 (size: 5.9 KB, free: 267.3 MB)
14/12/02 15:57:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 6) in 41723 ms on spark-worker-gce-1.weave.local (2/5)
14/12/02 15:57:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-worker-aws-2.weave.local:37387 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:57:55 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 9) in 42390 ms on spark-worker-aws-2.weave.local (3/5)
14/12/02 15:58:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-worker-aws-0.weave.local:43691 (size: 5.9 KB, free: 265.1 MB)
14/12/02 15:58:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 7) in 52366 ms on spark-worker-aws-0.weave.local (4/5)
14/12/02 15:58:05 INFO BlockManager: Removing broadcast 2
14/12/02 15:58:05 INFO BlockManager: Removing block broadcast_2_piece0
14/12/02 15:58:05 INFO MemoryStore: Block broadcast_2_piece0 of size 1013 dropped from memory (free 277793036)
14/12/02 15:58:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-shell.weave.local:47051 in memory (size: 1013.0 B, free: 265.1 MB)
14/12/02 15:58:05 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
14/12/02 15:58:05 INFO BlockManager: Removing block broadcast_2
14/12/02 15:58:05 INFO MemoryStore: Block broadcast_2 of size 1568 dropped from memory (free 277794604)
14/12/02 15:58:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-worker-aws-1.weave.local:34187 in memory (size: 1013.0 B, free: 265.1 MB)
14/12/02 15:58:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-worker-gce-2.weave.local:42653 in memory (size: 1013.0 B, free: 267.3 MB)
14/12/02 15:58:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-worker-gce-1.weave.local:56687 in memory (size: 1013.0 B, free: 267.3 MB)
14/12/02 15:58:06 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-worker-aws-2.weave.local:37387 in memory (size: 1013.0 B, free: 265.1 MB)
14/12/02 15:58:06 INFO BlockManagerInfo: Removed broadcast_2_piece0 on spark-worker-aws-0.weave.local:43691 in memory (size: 1013.0 B, free: 265.1 MB)
14/12/02 15:58:06 INFO ContextCleaner: Cleaned broadcast 2
14/12/02 15:58:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on spark-worker-gce-2.weave.local:42653 (size: 5.9 KB, free: 267.3 MB)
14/12/02 15:58:15 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 8) in 62227 ms on spark-worker-gce-2.weave.local (5/5)
14/12/02 15:58:15 INFO DAGScheduler: Stage 1 (count at <console>:35) finished in 62.228 s
14/12/02 15:58:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
14/12/02 15:58:15 INFO SparkContext: Job finished: count at <console>:35, took 62.233383437 s
res7: Long = 113

scala> 
